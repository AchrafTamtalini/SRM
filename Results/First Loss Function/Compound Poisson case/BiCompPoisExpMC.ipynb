{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEGCAYAAAB1iW6ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXjkVZ3v8fepSmXfl+rsW3d6gV6gSTc7NN2ijYCKzqOjXsdhRO6oXHueuYPozDPAFWfUy+iAI8qDiKhXdFwQEWQYBRoakKWBJtD0lu7O1lkqqexLZak694+qDkl3kko6la3yeT1PHpL6/X71+1al+PTJ+Z3fOcZai4iILH2OhS5AREQiQ4EuIhIlFOgiIlFCgS4iEiUU6CIiUSJmoU6cnZ1tS0tLF+r0IiJL0muvvdZmrc2ZaNuCBXppaSl79+5dqNOLiCxJxpjaybapy0VEJEoo0EVEooQCXUQkSixYH/pEhoeHaWhowOfzLXQpcyY+Pp7CwkJcLtdClyIiUWZRBXpDQwMpKSmUlpZijFnociLOWovX66WhoYGysrKFLkdEosyiCnSfzxe1YQ5gjCErK4vW1taFLkVEFsAjb5zgzicP0dg5QH56Aje/bw0fOrcgYs+/qAIdiNowPynaX5+ITOyRN07wlYffYmDYD8CJzgG+8vBbABELdV0UFRGZB3c+eXA0zE8aGPZz55OHInaORddCFxGJFr5hPy8fb+fpAy2c6Jx4sEdj50DEzhe2hW6MecAY4zHGvD3J9jRjzO+NMW8aY/YbY66PWHVhPPLGCS7+xtOUfflxLv7G0zzyxolZP6fT6eScc85h/fr1XHvttXR2do5ua2pq4pprrgHg4YcfZseOHaPbnn/+ec455xxGRkZ47LHHuO2222Zdi4gsPS3dPn7+Sh2f/clezv3qH/n0A6/wn3vriY+ZOG7z0xMidu7pdLk8COycYvsXgHestZuAbcC3jDGxsy9taif7o050DmB5tz9qtqGekJDAvn37ePvtt8nMzOSee+4Z3fbtb3+bz372swB8+MMfJj4+noceeoiRkRE+//nP873vfY+YmBiuvvpqHn30Ufr7+2dVi4gsfoGAZV99J9/+70Nc8x97OP9fn+IrD7/FO43d/MV5hfzo+i3su/W9fOMjG0lwOccdm+BycvP71kSslrBdLtba54wxpVPtAqSY4NW+ZKAdGJltYf/n9/t5p7F70u1v1HUy5A+Me2xg2M+Xfl3Fz1+pm/CYs/JTue3as6ddw4UXXkhVVdXoz7/5zW/42te+Nvrzf/zHf/Ce97yH/fv3s2XLFi666CIgeOFz27ZtPPbYY3z0ox+d9vlEZGno8Q2z50gbTx/0sPuQh7beIRwGzivJ4Es717Bj7QpWr0geNwji5IXPxT7K5bvAo0AjkAJ8zFobmGhHY8yNwI0AxcXFszrpqWEe7vGZ8vv9PPXUU3zmM58B4Pjx42RkZBAXFze6T3l5OR/72Mf47ne/y9GjR8cdX1lZyZ49exToIlHiWGsvTx/08PRBD68cb2ckYElLcHH56hx2rHNzWUUOGUlTd0586NyCiAb4qSIR6O8D9gHbgZXAH40xe6y1pzWvrbX3AfcBVFZWTrk6dbiW9MXfeJoTE1xMKEhP4D//54XTLv5UAwMDnHPOOdTU1HDeeedx5ZVXAsH+85yc8TNWBgIB/vSnP5GcnExtbS3Z2dmj29xuN42NjWdch4gsrKGRAK/WtPPUAQ/PHPJwvK0PgNUrkrnh0nK2r3WzuTidGOfiGSwYiUC/HviGtdYC1caY48Ba4JUIPPekbn7fmnFjOiEy/VEn+9C7urq45ppruOeee/jiF79IQkLCaVMS3HPPPaxfv5477riDL3zhC/z5z38e/RPL5/ORkBC5ix0iMvdaewbZfSjYCt9zpI3ewRFiYxxcWJ7F9ReXcsUaN0WZiQtd5qQiEeh1wA5gjzFmBbAGOBaB553SXPdHpaWl8Z3vfIcPfvCDfO5zn2P16tXU1NSMbm9ububb3/42r7zyCjk5OfzgBz/g/vvvH71oevjwYdavXx+RWkRkblhr2d/YzVMHPDx9yMOb9cFRbStS47h2Uz7b17q5eFUWibFLY4R32CqNMT8nOHol2xjTANwGuACstfcCdwAPGmPeAgxwi7W2bc4qHmOu+6POPfdcNm3axC9+8Qs+9alPsXLlSqqrq1m1ahV///d/z5e+9KXRbpi77rqLSy+9lI985CNkZmbyzDPP8PWvf33OahORM9M3OMLz1W08E+oP9/QMYgycU5TO/75yNdvXuTkrL3VJ3tU9nVEuHw+zvRF4b8QqWmC9vb3jfv79738/+v1NN93Egw8+yNe+9jUeeuihcfsVFRWNtuBbWloYGBhgw4YNc16viIRX5+3n6YMtPHXQw8vH2hnyB0iJi+Gy1TlsX+vm8jU5ZCfHhX+iRW5p/B2xSFx33XV4vd6w+9XV1fGtb31rHioSkYkM+wO8VtvBMwc9PHXQQ7Un2FArz0niry4sYfs6N1tKM3EtoguakaBAn6Ebbrgh7D5btmyZh0pEZKz2viGePezhqQMenjvcSrdvBJfTcH5ZFp/YWsz2tW5Ks5MWusw5pUAXkSXJWsvB5p7RseGv13VgLWQnx7FzfS7b17q5pCKH5LjlE3PL55WKyJI3MOTnxaPBOzSfOeihsSs4lHhDQRpf3F7B9rVuNhSk4XAsvQuakaBAF5FF7UTnQLAVfqCFF496GRwJkBjr5NKKbHa9p4Ir1rhxp8YvdJmLggL9DBw8eJDrr7+e119/nX/5l3/hH/7hHxa6JJGo4Q9Y3qjrGO1KOdjcA0BxZiIf31rMjnVutpZlEhfjDPNMy8/SDvSqX8JTX4WuBkgrhB23wsa5nzslMzOT73znOzzyyCNzfi6R5aCrf5hnj7Ty9IEWnj3cSkf/MDEOQ2VpBv/0/nVcsdbNypykJTk2fD4t3UCv+iX8/oswHJrPpas++DPMKtRramrYuXMnl1xyCS+99BKbNm3i+uuv57bbbsPj8fCzn/2MrVu34na7efzxxyPwQkSWH2st1Z5engq1wl+r7cAfsGQmxXLFGjfb17m5tCKHtATXQpe6pCzeQH/iy9D81uTbG14F/+D4x4YH4Hc3wWs/nviY3A1w1TfCnrq6uppf/epX3HfffWzZsoWHHnqI559/nkcffZR//dd/VctcZBJTLYLsG/bz0jHv6Njwho5gY2xdXiqfu3wlV6x1c05ROs5lekEzEhZvoIdzapiHe3wGysrKRu/yPPvss9mxYwfGGDZs2DBuPhcReddEiyB/+TdVvHi0jfa+YV6obmNg2E+8y8Elq7L53LaVXLHGHdEVe5a7xRvo4VrS/74+2M1yqrQiuH52XSFj5zx3OByjPzscDkZGZr12h0hUuvPJQ6ctguwbCfDLvQ0UpCfwF+cVsn2dmwvLs4h36YLmXFi8gR7OjlvH96EDuBKCj4vIvGntGeS5w60Trk8AwRn7nr/lCl3QnAdLN9BPXvhcgFEuzc3NVFZW0t3djcPh4K677uKdd94hNTV1zs8tstBG/AH21Xey+1Aruw97ePtEcC0bh4HABMvW5KcnKMzniQmuSzH/Kisr7d69e8c9duDAAdatW7cg9cyn5fI6JXp4un3sPtzKs4da2XMkOE+K02HYXJzOtjVuLl+dw5HmHv7xkbdPW3Tm6x/eMKfTXC83xpjXrLWVE21bui10EZkzw/4Ar9d2sPtwK7sPtXKgKdgKd6cE50m5fLWbSyqyxw0rXF+QhnGYOV0EWaamQBcRAJq6Bnj2UDDAX6huo2dwhBiH4bySDG7ZuZbLV+ewLi9lyu6TuV50RqamQBdZpoZGAuytbR8N8UMtwVvs89LiuWZTHpevzuGiVdmkxuvmnqVCgS6yjJzoHGD3IQ+7D7XyYnUbfUN+XE7DltJMvrJ5LdvWuFm9IlkXMZcoBbpIFBsc8fPq8Q52H/Lw7OFWjoRW7ilIT+BD5xaMtsKX05zh0Uy/RZEoU9/ePxrgLx710j/kJ9bp4PzyTD62pYhta3JYmaNWeDRSoJ+Bn/3sZ3zzm98EIDk5me9///ts2rRpgauS5co37Ofl4+2jIX6stQ8ITjf7F+cVcvnqHC5cmUVirP53j3ZL+jf8+LHHufv1u2nuayY3KZddm3dxdfnVc37esrIynn32WTIyMnjiiSe48cYbefnll+f8vCIn1bT1jQb4n4958Q0HiItxcEF5Fv/j/BK2rcmhLFvTzS43SzbQHz/2OLe/eDs+f3AJqqa+Jm5/8XaAWYX6dKbPveiii0b3v+CCC2hoaJjVaxEJZ2AoOFPhs4db2X3IQ423H4Cy7CT+cksxl6/J4YKyLBJiNUfKcrZoA/2br3yTg+0HJ91e1VrFUGBo3GM+v49bX7iVXx/+9YTHrM1cyy1bbwl77plMn/vDH/6Qq666apqvSmS8yaabtdZyrK0vOKTwcCsvHwsuvRbvcnBheRbXX1zGtjU5lGRF9yr2MjOLNtDDOTXMwz0+E9OdPveZZ57hhz/8Ic8///yszynLz0TTzX7p11X8am89dR391LcHJ7sqz0nik6FulK1lmZqpUCa1aAM9XEv6vb9+L019Tac9npeUx492/mhW557O9LlVVVXccMMNPPHEE2RlZc3qfLI8ffO/Dp423eyQP8CLR73sWOfmxstWsm11DkWZiQtUoSw1izbQw9m1ede4PnSAeGc8uzbvmvNz19XV8eEPf5if/vSnrF69es7PJ0ufb9jPgaZuqhq6eLOhk6qGLpq6fJPuf/+nt8xjdRItwga6MeYB4BrAY61dP8k+24C7ABfQZq29PJJFTuTkhc+FGOXy1a9+Fa/Xy+c//3kAYmJiOHXmSFm+RvwBDrf0UtXQyZsNXVQ1dHKouYeR0Nyy2clxbCpMo6XbR4/v9AVTtIKPnKmw0+caYy4DeoGfTBToxph04EVgp7W2zhjjttZ6wp1Y0+dG/+tcDgIBy3FvH2+NaXnvb+zCNxwAIDU+ho2F6WwsTGNjYTqbitLITY3HGHNaHzpoulkJb1bT51prnzPGlE6xyyeAh621daH9w4a5yFJkraWxy0dV/bst77dOdI22shNcTtYXpPKJrSVsKgoGeGlW4qRjwU+GtqablUiJRB/6asBljNkNpAB3W2t/MtGOxpgbgRsBiouLI3BqkTMz1er0J7X1Dga7TerfDe+23uAoKpfTsDY3lQ9symdTYTobi9JYlZNMjNMxozo03axEUiQCPQY4D9gBJAB/Nsa8ZK09fOqO1tr7gPsg2OUy0ZNZa6P67raFWiFK3jXh6vQPV3G4pYeUeBdVoa6Tk2tkGgMV7mS2rXGzKdR1sjYvhbgYDR+UxSUSgd5A8EJoH9BnjHkO2AScFujhxMfH4/V6ycrKispQt9bi9XqJj49f6FKWtTufPH24oG84wPd2HwWgJCuRzSUZ/PVFpWwsTGN9QRpJmo1QloBIfEp/B3zXGBMDxALnA/9+Jk9UWFhIQ0MDra2tEShrcYqPj6ewsHChy1h2uvqHefFoG88daeNE5+TDBffdeiXpibHzWJlI5Exn2OLPgW1AtjGmAbiN4PBErLX3WmsPGGP+C6gCAsD91tq3z6QYl8tFWVnZmRwqMs6IP8CbDZ08d7iNPUda2VffScBCSlwM8S7H6CiUsQrSExTmsqRNZ5TLx6exz53AnRGpSOQM1bf389yRVvYcbuOFo230+EZwGNhYmM5N2yu4rCKbTUXpPF7VNOFwwZvft2YBqxeZPXUMypLVOzjCn4962XOklT1H2jjeFpwHPD8tnqs35HHZ6hwuWpl1WqtbwwUlWinQZcnwByxvn+hiz5FWnjvSxuu1HYwELAkuJxeuzOLTF5Zw6eocyqcxD7iGC0o0UqDLotbUNcCew208d6SVF6rb6OgfBmB9QSqfvaycyypy2FySriGEIijQZZ6Fu6Gnf2iEl4+3syd0MfPkosbulDi2r13BZauzuWRVNlnJcZOdQmTZUqDLvJnohp6vPFxFQ2c/MQ4He4608urxDob8weXUtpYFFzW+tCKH1Su0qLFIOAp0mTd3PnnotBt6BoYD/NuTwXvQ1uam8OmLSrhsdQ5bSrWQg8hMKdBlzviG/Rxs7uGdxm7eaXr3VvqJvPyPO1iRqjtoRWZDgS4R0d43NBrc+xu7eaexm6OtvYSmACclPoZYp4Mh/8Q39CjMRWZPgS4zYq2lvn2A/Y1dvNPUHQrx7nGr7+SnxXNWfipXbcjjrLxUzs5PpTAjgd/ta9QNPSJzSIEukxoaCXC4pefd4G7s5kBTNz2Dwfm/nQ7DypwkLijP4qy8VM7KT+WsvFQykia+fV439IjMLQW6ANA1MMyBUHDvD7W6qz09DPuDfSaJsU7W5aXyoXMLODs/GN6rV6TM+MKlbugRmTsK9GXGWktTl2+0n/tkn3dDx7sXLHNS4jgrL5Ur1uSMtrpLs5JwODRsUGQxU6BHsRF/gKOtfbzT1DWu5d0ZutvSGCjLTuKconQ+cX7xaLeJO0UXKEWWIgX6EjLVXZZ9gyMcbO4e0/Lu5mBzD0MjwVElcTEO1uamcNX6XM7KT+OsvFTW5qZo4QaRKGIWakm0yspKu3fv3gU591I00QrxMQ7D+oJUugZGqPH2cfJXmZHo4qz8VM4OBfdZ+amUZyfNeL1LEVl8jDGvWWsrJ9qm5tkiZa2ludvHkZZejnh6+dZ/n36X5UjA8taJbq5ct4LrxlyszE2N123yIsuQAn2BBQKWho4Bjnh6qPYEw/uIp5ejnl56Q8MDwx1/76fOm4dKRWSxU6DPk2F/gFpvP9Vjg7ull2NtveOWQ3OnxFGxIpmPbC5g1YoUKtzJVLiT+cB3X5jw1vn89IT5fBkisogp0CPMN+zneFvfaGhXe3o40tJLjbdvdEw3BG93r1iRzEUrs6hYkcwqdwqr3MmkJbgmfN6b37dGd1mKyJQU6Geob3CEo62941rbR1t7qfX2jc5f4jBQkpXEypxk3nPWilBrO4XynKQZjy7RXZYiEo4CPYyugWGqx7S0g63u3nHdHy6noSw7iXV5KVy7KZ8KdzKr3MmUZSdFdApY3WUpIlNRoId4ewdHL0hWt/RQ3RpsdXt6Bkf3iYtxsDInmcrSDD7uLmKVO9hVUpKViEtDAkVkgS2rQLfW0tI9yJFQa7u6tZfqll6OeHpG16oESI6LYaU7mctW54y2tivcKRRkJODU7e8iskgtqUAPtx7lSYGA5UTnwLvBPWYoYM+YoYDpiS4q3MnsXJ8XCu1kKlYkaxy3iCxJSybQJ1qP8ssPV9HS46MkM4mjrb0caekJBnfr+KGAOSlxVLiTuW5zQajFnULFimSykmIV3CISNZZMoE+0HqVvOMDX/3Bw9OeC9ARWuZO5oDxrtLW9KieFtMSJhwKKiESTsIFujHkAuAbwWGvXT7HfFuAl4GPW2l9HrsSgxinWo3z0potZmZOsiaZEZFmbztCMB4GdU+1gjHEC3wSejEBNE5rsjsiC9AQ2FqYrzEVk2Qsb6Nba54D2MLv9L+A3gCcSRU3k5vetIeGUMd26U1JE5F2zbtYaYwqA64DtwJYw+94I3AhQXFw8o/PoTkkRkalFop/iLuAWa60/3IgRa+19wH0QnA99pifSnZIiIpOLRKBXAr8IhXk28H5jzIi19pEIPLeIiEzTrAPdWlt28ntjzIPAYwpzEZH5N51hiz8HtgHZxpgG4DbABWCtvXdOqxMRkWkLG+jW2o9P98mstX89q2pEROSMaYpAEZEooUAXEYkSCnQRkSihQBcRiRIKdBGRKKFAFxGJEgp0EZEooUAXEYkSCnQRkSihQBcRiRIKdBGRKKFAFxGJEgp0EZEooUAXEYkSCnQRkSihQBcRiRIKdBGRKKFAFxGJEgp0EZEooUAXEYkSCnQRkSihQBcRiRIKdBGRKKFAFxGJEgp0EZEooUAXEYkSCnQRkSgRNtCNMQ8YYzzGmLcn2f5JY0xV6OtFY8ymyJcpIiLhTKeF/iCwc4rtx4HLrbUbgTuA+yJQl4iIzFBMuB2stc8ZY0qn2P7imB9fAgpnX5aIiMxUpPvQPwM8MdlGY8yNxpi9xpi9ra2tET61iMjyFrFAN8ZcQTDQb5lsH2vtfdbaSmttZU5OTqROLSIiTKPLZTqMMRuB+4GrrLXeSDyniIjMzKxb6MaYYuBh4FPW2sOzL0lERM5E2Ba6MebnwDYg2xjTANwGuACstfcCtwJZwPeMMQAj1trKuSpYREQmNp1RLh8Ps/0G4IaIVSQiImdEd4qKiEQJBbqISJRQoIuIRAkFuohIlFCgi4hECQW6iEiUUKCLiEQJBbqISJRQoIuIRAkFuohIlFCgi4hECQW6iEiUUKCLiEQJBbqISJRQoIuIRAkFuohIlFCgi4hECQW6iEiUUKCLiEQJBbqISJRQoIuIRAkFuohIlFCgi4hECQW6iEiUUKCLiEQJBbqISJQIG+jGmAeMMR5jzNuTbDfGmO8YY6qNMVXGmM2RL1NERMKZTgv9QWDnFNuvAipCXzcC3599WSIiMlNhA91a+xzQPsUuHwR+YoNeAtKNMXmRKlBERKYnEn3oBUD9mJ8bQo+dxhhzozFmrzFmb2trawROLSIiJ0Ui0M0Ej9mJdrTW3metrbTWVubk5ETg1CIiclIkAr0BKBrzcyHQGIHnFRGRGYhEoD8K/FVotMsFQJe1tikCzysiIjMQE24HY8zPgW1AtjGmAbgNcAFYa+8F/gC8H6gG+oHr56pYERGZXNhAt9Z+PMx2C3whYhWJiMgZ0Z2iIiJRQoEuIhIlFOgiIlFCgS4iEiUU6CIiUUKBLiISJRToIiJRIuw4dBERiYzHd/8zdx/7Lc0OyA3ArvLruHrbHRF7fgW6iMg8eHz3P3P78d/icwbnM2xywu3HfwsQsVBXl4uIyBzp9XWz//hTPP7Sv/G147/F5xg/Oa3PYbj72G8jdj610EVEZmFoZJAGTxU1Ta9S2/YOtd211Ay0Uuvvp80xZibxiSYaB5oj2KxWoIuIhBGwAZq9h6g58Qq1rW9T23WMmoEWaod7aDR+AubdtM70+ym1MVzqSqMkKY/SjFWU5Gzkc69+jWbn6c+dG4hcnQp0ERHAWktnzwlqT7xETcub1HZWU9PXRM1wF/UMMzgmtBMDAUoCDjbEJHNN4gpK0sopzV5PccEWUrPXgfP0aP077/5gH/qYbpf4gGVX+XURew0KdBFZVvp9ndQ1/Jmaln3Uth+itreB2sEOauwg3WPCNsZaCv1Q6kzk4oQ8SlJKKM0+i5K8SnJyz8W44md03pMXPudylIsJzn47/yorK+3evXsX5NwiEt2Ghwc40bSX2qbXqPEepLanllqfl5rAAJ5T+qxz/QFKTDyl8VmUJBdSkrmG0tzN5BdsJSY+bWFewBSMMa9Zaysn2qYWuogsSdbvx9P6FrWNr1DTtp/arhpqBzzUjvTR4AgwMqaLJC0QoJRYLojNpjSpgJKMVZSsOIfiggtISMldwFcRWQp0EVm8rKWr4xi1J16i1vMWNV1Hqe1rona4h1rjZ+CU/uhi66TClcqVibmUpK+kJGcDpQUXkJ65Eswkw0yiiAJdRCKn6pfw1FehqwHSCmHHrbDxo2EP8/U0U3/iZWo9+6hpP0xNXyO1Q53U2iE6nO/2kTitpSDgoCQmicoEN6WpJZRkr6c0fwtu9wYcE1yMXE6W96sXkcip+iWP/+lm7k5NpDmjkNwRP7v+dDNXA2z8KH5fN42Nr1Db/Dq13kPU9NRTO+il1vpochjsmBZ0TgBKHPFsj8+lLKWYkqx1lORtpjB3C67YhAV7iYudLoqKSEQ8fs96bk+0+BzjW9Srh4YZdLqod8LwmNBODlhKTRwlcRmUJBdSmrmakhXnUlJwPkkJmQvxEpYEXRQVkYgJDPtoaXqNuubXqfcepK67lnpfK7uTYMSMH0LiN4YjsS4ud2WzLSmX0owKSnI2UlJwPpmpRZhl0K89nxToInKakaF+mppfo775Deq8B6nrrqPe10qdv58Gh2VoTBC7rKWQGEYmeS4/cNcnd89H2cueAl1kmRoe6qehaS/1zW9Q336Qup466gbaqPf3c8Jhxw37iw9YioihLDaDyxNXUJRWTnH22RQXbMGduRqnw8l7H7qEpuGu086TG5s+ny9rWVOgi0Qx32AvDc17qWt+g3rvoWBo+7zUB/ppMnbcHCRJAUsxMayJzeDKxFyK08opyjmb4vyt5GRWYBxTzyK164KvcPvz/4zPDo8+Fm9c7LrgK3P2+mQ8BbrIEtc32E1946vUt7xJXfsh6nvqqRv0Uufvp+WUDE4LBCjGxSZXJtcm5lKcXk5RznqK87eSkbEybGhP5eryqwG4+/W7ae5rJjcpl12bd40+LnNPgS6ygKa7gk23r4P6pteoa9lHXfsh6noaqB/0UucfwHtKBmf5g6F9fmwmRYm5FKevpDhnPUX5W0jLXDWnN9hcXX61AnwBKdBFFshEK9jcevy3vNb6JtmJbup6G6gfbKfOP0DnKaHtHvFTbGK5PDaTosQ8ijNWUpyzgaL8rSRllC2LuyLldNMKdGPMTuBuwAncb639xinb04D/BxSHnvPfrLU/inCtIkuStZZuXyct7YfxtB/G01lDS28DDza/cNoKNkMOw6/6j2P6jpHvD1BkYrnSlUlxcj5F6eUU52ykMH8LCQptmUDYQDfGOIF7gCuBBuBVY8yj1tp3xuz2BeAda+21xpgc4JAx5mfW2qE5qVpkliK1WO/wyBCtHdV4vAdp6TyGp7seT38zLb52PEM9eAIDePCPm0t71CR5bKxl7wceJTa9FGbRpy3Lz3Ra6FuBamvtMQBjzC+ADwJjA90CKSZ4l0Ay0A6TDksVWVDTWazXBgJ0dzfg8R7E01GNp6uOlr5GPANteIa68Pj7abEjtE+Qt7EBiztgcZsY1jsTccem4U7Ixp2Ux4rUYtwZq8jJWsM1v/sATZOsYBObWT5nr1+i13QCvQCoH/NzA3D+Kft8F3gUaARSgI9Za09bWMkYcyNwI0BxcfGZ1Csya3cfezfMT/I5DLcff5hf1fwBT2CIVmNP6w4ByPAHcK01HlkAAAvMSURBVOPE7YznrNgsVsRn4k7MxZ1aiDu9nBVZq0nLqMBMY76RXeXXzfkKNrK8TCfQJ/rD8NQJYN4H7AO2AyuBPxpj9lhru8cdZO19wH0QnMtl5uWKTIO10N9Ot2c/dZ7gqjR1PfXUDrRSN9I7YasYwGcMFsP6uCzccem4E924kwtwp5XhzlyFO3sdsQkZEStzPlawkeVlOoHeABSN+bmQYEt8rOuBb9jgTF/VxpjjwFrglYhUKXKqoT7orKOv7RC1nreo66ymtvcEdT4vtYEB6mIcdDjfTW5jLbk4KY5NIXGkm/4Jmil5Afjx38zvhHFXb7tDAS4RM51AfxWoMMaUASeAvwQ+cco+dcAOYI8xZgWwBjgWyUIlOkz7YqR/BLoboKOW/vYj1Le+Q23Xcer6m6kd6qTOjFAb48IbM7657XbFUOJawfbEFZSkllGcvY6S3M0UZq4mPiZ+tAZ1dUg0Chvo1toRY8xNwJMEhy0+YK3db4z529D2e4E7gAeNMW8R7KK5xVrbNod1yxI08cXIh8FbzY6sTdSF5hOp7W+lzt9HbYyTOlcMrTFjPqZOyE5MpDg2ncuS8ylOX0VJzvrgjTMpRSS6EsPWoa4OiVaaD10iy1rwdUJPC/Q2Q08zge4mOnvq+Yum/6I15vQObIcdP6cIQKYjjuL4LIqTiyjJrKA4ZwMlaWUUpxaT5Eqar1cjsuhoPnSZvUAABtqhpxl6m/F3N9LRVYu35wTe3ma8vjbaB7vwjvTRZsDrdOB1OvE6nXQ4HfiNgQnCHCAAfH7DZylJX0VJagnFqcWkxKbM7+sTiQIK9OUu4Ie+VuhpZqSnkc6O47R11+HtbcLb34p3sAPvcA9evw+v0+B1OGmLcdLpcIxvVTuBRHCRQnZMIlmxqeTGZ3J2Ui5ZKflkJedz70tfp3OCoYB5Afjc5i/O32sWiVIK9CVkRnc3+oeht4XhrhN0dB7D23kcb08j3v4W2nxevEPdeEf68dphvE4H7U4nHQ7HuHUdAYiBuJgYspzZZLmSyY/LYEOim6zkPLJSi8lKziUrPoushOBXiitl0lVo0lsO6mKkyBxSoC8Rk03kdKDxFVYm5eMdaMM72Il3pBdvYBAvfrxOJ53Oibs5EmIMmbFJZMUkURSXxjnx2WQl5ZKVUkB2ehlZSSuCIR2fRZIrKSJLhelipMjc0kXRhWQt1tfFQHcDHV11dHTX097bRGe/hw6fl/bBLjqHe2gfGeAFM8TwBN0VYyVYyDKuYJeHK5WshEyyEtzBLo/UErLSy8hKcpOdkD2t0SAisvjoouh8CQQIDLTT1VkTDOieBjr6mujob6PD107HYBcdI310+H102GE6CNDhMAxOMgFTjIUMDBnOWIYn+3fXWv5w3R/ISlRIiyx3CvSpBPwM9TTT0VVDR1ct7T0n6OxroWOgjXZfB53D3XQM99Me8NFpR+gw9vSLhWMkWUjHSWZMLDnOVCpcyWTGpZORkEVGopuM5DwyUovISCshIyWfZFfyaFfHex9YP+Et63kBKErTvDgissQCfbZTntrhQfq66+noqqG9q46O3iY6+j10DLTRMdhJx3APHSMDdAQG6bB+OhzQN0nr2WEt6daQbmLIiEmgPCaR9NgUMuIzyIzPJj3JTUZKAZmpxaSnl5CRtII4Z9wZv3ZN5CQi4SyZQJ9sytOeAS+VK6+io/tEsHujz0O7r53OwS46RnppHxmg0w6Ndm8MT9J6jrOWDOsgw7jIcCVT7EomIzaVjPhMMhKyyUjOJSO5INh6TishNSETp2OSWZ7mgC4oikg4S+aiaLDLYfojLVIClkycpDtcZDgTyHQlkx6bRmZCJhmJbtKT88hMKSIjvYSM1BISYiMzkkNEZC5FxUXR5skWbrGWOys+Odr/nJlWSlpaES5n7LzWJyKy0JZMoOcGmPSi4M6LvzL/BYmILDJLZsHCXeXXER8Y3z2ki4IiIu9aMi10XRQUEZnakrkoKiIiU18UXTJdLiIiMjUFuohIlFCgi4hECQW6iEiUUKCLiESJBRvlYoxpBWrn8BTZQNscPv9cUd3zS3XPL9U9eyXW2pyJNixYoM81Y8zeyYb2LGaqe36p7vmluueWulxERKKEAl1EJEpEc6Dft9AFnCHVPb9U9/xS3XMoavvQRUSWm2huoYuILCsKdBGRKLGkA90Yk2mM+aMx5kjovxkT7LPGGLNvzFe3MebvQttuN8acGLPt/Yul7tB+NcaYt0K17Z3p8QtRtzGmyBjzjDHmgDFmvzFm15ht8/Z+G2N2GmMOGWOqjTFfnmC7McZ8J7S9yhizebrHzqVp1P3JUL1VxpgXjTGbxmyb8POySOreZozpGvO7v3W6xy5w3TePqfltY4zfGJMZ2rZg7/ekrLVL9gv4v8CXQ99/GfhmmP2dQDPBgfkAtwP/sFjrBmqA7Nm+7vmsG8gDNoe+TwEOA2fN5/sd+j0fBcqBWODNkzWM2ef9wBOAAS4AXp7usQtc90VARuj7q07WPdXnZZHUvQ147EyOXci6T9n/WuDphX6/p/pa0i104IPAj0Pf/xj4UJj9dwBHrbVzeYfqdMy07kgff6bCntda22StfT30fQ9wACiYp/pO2gpUW2uPWWuHgF8QrH2sDwI/sUEvAenGmLxpHrtgdVtrX7TWdoR+fAkonKfapjKb92xRv9+n+Djw83mp7Awt9UBfYa1tgmCQAO4w+/8lp/9Cbgr9+frAfHVdMP26LfDfxpjXjDE3nsHxkTaj8xpjSoFzgZfHPDwf73cBUD/m5wZO/0dlsn2mc+xcmem5P0Pwr4yTJvu8zLXp1n2hMeZNY8wTxpizZ3jsXJj2uY0xicBO4DdjHl6o93tSi34JOmPMn4DcCTb90wyfJxb4ADB2RenvA3cQ/MXcAXwL+Jszq/S080Wi7outtY3GGDfwR2PMQWvtc5GobzIRfL+TCX74/85a2x16eM7e71NPP8Fjp47PnWyf6Rw7V6Z9bmPMFQQD/ZIxD8/75+VkORM8dmrdrxPs6uwNXTt5BKiY5rFzZSbnvhZ4wVrbPuaxhXq/J7XoA91a+57JthljWowxedbaptCfy54pnuoq4HVrbcuY5x793hjzA+CxSNQceu5Z122tbQz912OM+S3BPxGfA2byuue9bmOMi2CY/8xa+/CY556z9/sUDUDRmJ8LgcZp7hM7jWPnynTqxhizEbgfuMpa6z35+BSfl7kWtu4x/6hjrf2DMeZ7xpjs6Rw7h2Zy7tP+ul/A93tSS73L5VHg06HvPw38bop9T+v/CoXSSdcBb0e0usmFrdsYk2SMSTn5PfDeMfXN5HVH0nTqNsAPgQPW2m+fsm2+3u9XgQpjTFnoL7O/JFj7WI8CfxUa7XIB0BXqRprOsXMl7LmNMcXAw8CnrLWHxzw+1edlMdSdG/psYIzZSjB7vNM5diHrDtWbBlzOmM/7Ar/fk1voq7Kz+QKygKeAI6H/ZoYezwf+MGa/RIIfnrRTjv8p8BZQRfAXmbdY6iZ45f3N0Nd+4J/CHb9I6r6E4J+tVcC+0Nf75/v9JjiK5TDBUQz/FHrsb4G/DX1vgHtC298CKqc6dh4/0+Hqvh/oGPPe7g33eVkkdd8UqutNghdzL1oK73fo578GfnHKcQv6fk/2pVv/RUSixFLvchERkRAFuohIlFCgi4hECQW6iEiUUKCLiEQJBbose8aYUmPMwo8hFpklBbpIcEy6/l+QJU8fYlmWQq3yA8aY7xGcZyTBGPMDE5zD/b+NMQmh/c4xxrwUmlDst/M4gZvIjCnQZTlbA/yE4IyQRcA91tqzgU7gI6F9fgLcYq3dSPCO0tsWolCR6VCgy3JWa4NzoQMct9buC33/GlAamsMj3Vr7bOjxHwOXzXeRItOlQJflrG/M94NjvvezBGYiFTmVAl1kEtbaLqDDGHNp6KFPAc9OcYjIglIrRGRqnwbuDa1Ycwy4foHrEZmUZlsUEYkS6nIREYkSCnQRkSihQBcRiRIKdBGRKKFAFxGJEgp0EZEooUAXEYkS/x9waBuhJ//jKgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../..')\n",
    "from Library.lossSRM import LossAbs\n",
    "from Library.CompoundPoisson2 import CompoundPoisson2\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCLossFunction(LossAbs):\n",
    "    def __init__(self, X, alpha, c = None):\n",
    "        self.__alpha = alpha\n",
    "        super(MCLossFunction, self).__init__(X, c)\n",
    "        \n",
    "    def shortfall_risk(self, m = None):\n",
    "        m = self._check_argument(m)\n",
    "        #This substract from the col i of X, m_i\n",
    "        #X is a matrix of dim columns and N rows where N is the sample's length\n",
    "        x_minus_m = np.subtract(self.X, m)\n",
    "        #axis = 1 means we sum the elements of each row\n",
    "        mean_sum = np.mean(np.sum(x_minus_m, axis = 1))\n",
    "        pos_part = np.maximum(x_minus_m, 0)\n",
    "        mean_sum_2 = np.mean(np.sum(pos_part ** 2, axis = 1))\n",
    "        cross_term = 0.\n",
    "        for i in range(self.dim):\n",
    "            for j in range(i + 1, self.dim):\n",
    "                cross_term += np.mean(np.multiply(pos_part[:, i], pos_part[:, j]))\n",
    "        return mean_sum + 0.5 * mean_sum_2 + self.__alpha * cross_term\n",
    "    \n",
    "    def shortfall_risk_jac(self, m):\n",
    "        m = self._check_argument(m)\n",
    "        x_minus_m = np.subtract(self.X, m)\n",
    "        pos_part = np.maximum(x_minus_m, 0) \n",
    "        pos_part_mean = np.mean(pos_part, axis = 0)\n",
    "        cross_jac = []\n",
    "        for i in range(self.dim):\n",
    "            temp = 0.\n",
    "            indic_i = np.sign(pos_part[:, i])\n",
    "            for k in range(self.dim):\n",
    "                if k != i:\n",
    "                    temp += self.__alpha * np.mean(np.multiply(pos_part[:, k], indic_i))\n",
    "            cross_jac.append(temp)\n",
    "        return pos_part_mean + 1. + cross_jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.8457855986439711\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.8457855986439711\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.8457855986439711\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.8457855986439711\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.8457855986439711\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.8457855986439711\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.8457855986439711\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.8457855986439711\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "763 ms ± 64.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "[[ 1.         -0.79862383]\n",
      " [-0.79862383  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Case: rho = -0.9, alpha = 1\n",
    "\n",
    "#M is the length of the sample\n",
    "\n",
    "#Modifier distr en utilisant le getter!!!!!!!!!\n",
    "M = 1000000\n",
    "rho_gauss = [[1, -0.9],[-0.9, 1]]\n",
    "lam = [2, 2]\n",
    "T = 1\n",
    "lam_exp = [3, 3]\n",
    "obj = CompoundPoisson2(T, lam,  M, lam_exp, rho_gauss)\n",
    "distr = obj.get_compound_distr()\n",
    "rho_pois = obj.rho_pois()\n",
    "\n",
    "c = 1.\n",
    "alpha  = 1.\n",
    "loss = MCLossFunction(distr, alpha, c)\n",
    "maxiter = 3500\n",
    "\n",
    "init = np.ones(loss.dim)\n",
    "cons = ({'type': 'ineq',\n",
    "         'fun' : lambda x: loss.ineq_constraint(x),\n",
    "         'jac' : lambda x: loss.ineq_constraint_jac(x)})\n",
    "%timeit res = minimize(loss.objective, init, jac = loss.objective_jac, constraints = cons, method='SLSQP',options={'maxiter': maxiter, 'disp': True})\n",
    "\n",
    "print(rho_pois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.8687881101062366\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "     fun: 0.8687881101062366\n",
      "     jac: array([1., 1.])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 6\n",
      "     nit: 5\n",
      "    njev: 5\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.43403885, 0.43474926])\n",
      "[[ 1.         -0.45001621]\n",
      " [-0.45001621  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Case: rho = -0.5, alpha = 1\n",
    "\n",
    "#M is the length of the sample\n",
    "M = 1000000\n",
    "rho_gauss = [[1, -0.5],[-0.5, 1]]\n",
    "lam = [2, 2]\n",
    "T = 1\n",
    "lam_exp = [3, 3]\n",
    "obj = CompoundPoisson2(T, lam,  M, lam_exp, rho_gauss)\n",
    "rho_pois = obj.rho_pois()\n",
    "distr = obj.get_compound_distr()\n",
    "\n",
    "c = 1.\n",
    "alpha  = 1.\n",
    "loss = MCLossFunction(distr, alpha, c)\n",
    "maxiter = 3500\n",
    "\n",
    "init = np.ones(loss.dim)\n",
    "cons = ({'type': 'ineq',\n",
    "         'fun' : lambda x: loss.ineq_constraint(x),\n",
    "         'jac' : lambda x: loss.ineq_constraint_jac(x)})\n",
    "res = minimize(loss.objective, init, jac = loss.objective_jac, constraints = cons, method='SLSQP',options={'maxiter': maxiter, 'disp': True})\n",
    "print(res)\n",
    "print(rho_pois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.8998626723928684\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "     fun: 0.8998626723928684\n",
      "     jac: array([1., 1.])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 6\n",
      "     nit: 5\n",
      "    njev: 5\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.44945303, 0.45040965])\n",
      "[[1.00000000e+00 3.74407013e-04]\n",
      " [3.74407013e-04 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#Case: rho = 0, alpha = 1\n",
    "\n",
    "#M is the length of the sample\n",
    "M = 1000000\n",
    "rho_gauss = [[1, 0],[0, 1]]\n",
    "lam = [2, 2]\n",
    "T = 1\n",
    "lam_exp = [3, 3]\n",
    "obj = CompoundPoisson2(T, lam,  M, lam_exp, rho_gauss)\n",
    "rho_pois = obj.rho_pois()\n",
    "distr = obj.compound_poisson2()\n",
    "\n",
    "c = 1.\n",
    "alpha  = 1.\n",
    "loss = MCLossFunction(distr, alpha, c)\n",
    "maxiter = 3500\n",
    "\n",
    "init = np.ones(loss.dim)\n",
    "cons = ({'type': 'ineq',\n",
    "         'fun' : lambda x: loss.ineq_constraint(x),\n",
    "         'jac' : lambda x: loss.ineq_constraint_jac(x)})\n",
    "res = minimize(loss.objective, init, jac = loss.objective_jac, constraints = cons, method='SLSQP',options={'maxiter': maxiter, 'disp': True})\n",
    "print(res)\n",
    "print(rho_pois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.9379178574160493\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "     fun: 0.9379178574160493\n",
      "     jac: array([1., 1.])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 6\n",
      "     nit: 5\n",
      "    njev: 5\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.46966394, 0.46825392])\n",
      "[[1.         0.46925279]\n",
      " [0.46925279 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Case: rho = 0.5, alpha = 1\n",
    "\n",
    "#M is the length of the sample\n",
    "M = 1000000\n",
    "rho_gauss = [[1, 0.5],[0.5, 1]]\n",
    "lam = [2, 2]\n",
    "T = 1\n",
    "lam_exp = [3, 3]\n",
    "obj = CompoundPoisson2(T, lam,  M, lam_exp, rho_gauss)\n",
    "rho_pois = obj.rho_pois()\n",
    "distr = obj.compound_poisson2()\n",
    "\n",
    "c = 1.\n",
    "alpha  = 1.\n",
    "loss = MCLossFunction(distr, alpha, c)\n",
    "maxiter = 3500\n",
    "\n",
    "init = np.ones(loss.dim)\n",
    "cons = ({'type': 'ineq',\n",
    "         'fun' : lambda x: loss.ineq_constraint(x),\n",
    "         'jac' : lambda x: loss.ineq_constraint_jac(x)})\n",
    "res = minimize(loss.objective, init, jac = loss.objective_jac, constraints = cons, method='SLSQP',options={'maxiter': maxiter, 'disp': True})\n",
    "print(res)\n",
    "print(rho_pois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.9666818089676164\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "     fun: 0.9666818089676164\n",
      "     jac: array([1., 1.])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 6\n",
      "     nit: 5\n",
      "    njev: 5\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.48375373, 0.48292808])\n",
      "[[1.        0.8601024]\n",
      " [0.8601024 1.       ]]\n"
     ]
    }
   ],
   "source": [
    "#Case: rho = 0.9, alpha = 1\n",
    "\n",
    "#M is the length of the sample\n",
    "M = 1000000\n",
    "rho_gauss = [[1, 0.9],[0.9, 1]]\n",
    "lam = [2, 2]\n",
    "T = 1\n",
    "lam_exp = [3, 3]\n",
    "obj = CompoundPoisson2(T, lam,  M, lam_exp, rho_gauss)\n",
    "rho_pois = obj.rho_pois()\n",
    "distr = obj.compound_poisson2()\n",
    "\n",
    "c = 1.\n",
    "alpha  = 1.\n",
    "loss = MCLossFunction(distr, alpha, c)\n",
    "maxiter = 3500\n",
    "\n",
    "init = np.ones(loss.dim)\n",
    "cons = ({'type': 'ineq',\n",
    "         'fun' : lambda x: loss.ineq_constraint(x),\n",
    "         'jac' : lambda x: loss.ineq_constraint_jac(x)})\n",
    "res = minimize(loss.objective, init, jac = loss.objective_jac, constraints = cons, method='SLSQP',options={'maxiter': maxiter, 'disp': True})\n",
    "print(res)\n",
    "print(rho_pois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.8071887602247589\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.8071887602247589\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.8071887602247589\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.8071887602247589\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.8071887602247589\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.8071887602247589\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.8071887602247589\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.8071887602247589\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "933 ms ± 46.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "[[ 1.         -0.79927638]\n",
      " [-0.79927638  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Case: rho = -0.9, alpha = 0\n",
    "\n",
    "#M is the length of the sample\n",
    "M = 1000000\n",
    "rho_gauss = [[1, -0.9],[-0.9, 1]]\n",
    "lam = [2, 2]\n",
    "T = 1\n",
    "lam_exp = [3, 3]\n",
    "obj = CompoundPoisson2(T, lam,  M, lam_exp, rho_gauss)\n",
    "rho_pois = obj.rho_pois()\n",
    "distr = obj.compound_poisson2()\n",
    "\n",
    "c = 1.\n",
    "alpha  = 0.\n",
    "loss = MCLossFunction(distr, alpha, c)\n",
    "maxiter = 3500\n",
    "\n",
    "init = np.ones(loss.dim)\n",
    "cons = ({'type': 'ineq',\n",
    "         'fun' : lambda x: loss.ineq_constraint(x),\n",
    "         'jac' : lambda x: loss.ineq_constraint_jac(x)})\n",
    "%timeit res = minimize(loss.objective, init, jac = loss.objective_jac, constraints = cons, method='SLSQP',options={'maxiter': maxiter, 'disp': True})\n",
    "\n",
    "print(rho_pois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.8068725791105906\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "     fun: 0.8068725791105906\n",
      "     jac: array([1., 1.])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 6\n",
      "     nit: 5\n",
      "    njev: 5\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.40377374, 0.40309884])\n",
      "[[ 1.         -0.45081054]\n",
      " [-0.45081054  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Case: rho = -0.5, alpha = 0\n",
    "\n",
    "#M is the length of the sample\n",
    "M = 1000000\n",
    "rho_gauss = [[1, -0.5],[-0.5, 1]]\n",
    "lam = [2, 2]\n",
    "T = 1\n",
    "lam_exp = [3, 3]\n",
    "obj = CompoundPoisson2(T, lam,  M, lam_exp, rho_gauss)\n",
    "rho_pois = obj.rho_pois()\n",
    "distr = obj.compound_poisson2()\n",
    "\n",
    "c = 1.\n",
    "alpha  = 0.\n",
    "loss = MCLossFunction(distr, alpha, c)\n",
    "maxiter = 3500\n",
    "\n",
    "init = np.ones(loss.dim)\n",
    "cons = ({'type': 'ineq',\n",
    "         'fun' : lambda x: loss.ineq_constraint(x),\n",
    "         'jac' : lambda x: loss.ineq_constraint_jac(x)})\n",
    "res = minimize(loss.objective, init, jac = loss.objective_jac, constraints = cons, method='SLSQP',options={'maxiter': maxiter, 'disp': True})\n",
    "print(res)\n",
    "print(rho_pois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.807653531425347\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "     fun: 0.807653531425347\n",
      "     jac: array([1., 1.])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 6\n",
      "     nit: 5\n",
      "    njev: 5\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.40349995, 0.40415358])\n",
      "[[1.         0.00104919]\n",
      " [0.00104919 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Case: rho = 0, alpha = 0\n",
    "\n",
    "#M is the length of the sample\n",
    "M = 1000000\n",
    "rho_gauss = [[1, 0],[0, 1]]\n",
    "lam = [2, 2]\n",
    "T = 1\n",
    "lam_exp = [3, 3]\n",
    "obj = CompoundPoisson2(T, lam,  M, lam_exp, rho_gauss)\n",
    "rho_pois = obj.rho_pois()\n",
    "distr = obj.compound_poisson2()\n",
    "\n",
    "c = 1.\n",
    "alpha  = 0.\n",
    "loss = MCLossFunction(distr, alpha, c)\n",
    "maxiter = 3500\n",
    "\n",
    "init = np.ones(loss.dim)\n",
    "cons = ({'type': 'ineq',\n",
    "         'fun' : lambda x: loss.ineq_constraint(x),\n",
    "         'jac' : lambda x: loss.ineq_constraint_jac(x)})\n",
    "res = minimize(loss.objective, init, jac = loss.objective_jac, constraints = cons, method='SLSQP',options={'maxiter': maxiter, 'disp': True})\n",
    "print(res)\n",
    "print(rho_pois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.8090806981606309\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "     fun: 0.8090806981606309\n",
      "     jac: array([1., 1.])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 6\n",
      "     nit: 5\n",
      "    njev: 5\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.40490401, 0.40417669])\n",
      "[[1.         0.46934819]\n",
      " [0.46934819 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Case: rho = 0.5, alpha = 0\n",
    "\n",
    "#M is the length of the sample\n",
    "M = 1000000\n",
    "rho_gauss = [[1, 0.5],[0.5, 1]]\n",
    "lam = [2, 2]\n",
    "T = 1\n",
    "lam_exp = [3, 3]\n",
    "obj = CompoundPoisson2(T, lam,  M, lam_exp, rho_gauss)\n",
    "rho_pois = obj.rho_pois()\n",
    "distr = obj.compound_poisson2()\n",
    "\n",
    "c = 1.\n",
    "alpha  = 0.\n",
    "loss = MCLossFunction(distr, alpha, c)\n",
    "maxiter = 3500\n",
    "\n",
    "init = np.ones(loss.dim)\n",
    "cons = ({'type': 'ineq',\n",
    "         'fun' : lambda x: loss.ineq_constraint(x),\n",
    "         'jac' : lambda x: loss.ineq_constraint_jac(x)})\n",
    "res = minimize(loss.objective, init, jac = loss.objective_jac, constraints = cons, method='SLSQP',options={'maxiter': maxiter, 'disp': True})\n",
    "print(res)\n",
    "print(rho_pois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.807517702957984\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "     fun: 0.807517702957984\n",
      "     jac: array([1., 1.])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 6\n",
      "     nit: 5\n",
      "    njev: 5\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.40400765, 0.40351005])\n",
      "[[1.         0.86024536]\n",
      " [0.86024536 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Case: rho = 0.9, alpha = 0\n",
    "\n",
    "#M is the length of the sample\n",
    "M = 1000000\n",
    "rho_gauss = [[1, 0.9],[0.9, 1]]\n",
    "lam = [2, 2]\n",
    "T = 1\n",
    "lam_exp = [3, 3]\n",
    "obj = CompoundPoisson2(T, lam,  M, lam_exp, rho_gauss)\n",
    "rho_pois = obj.rho_pois()\n",
    "distr = obj.compound_poisson2()\n",
    "\n",
    "c = 1.\n",
    "alpha  = 0.\n",
    "loss = MCLossFunction(distr, alpha, c)\n",
    "maxiter = 3500\n",
    "\n",
    "init = np.ones(loss.dim)\n",
    "cons = ({'type': 'ineq',\n",
    "         'fun' : lambda x: loss.ineq_constraint(x),\n",
    "         'jac' : lambda x: loss.ineq_constraint_jac(x)})\n",
    "res = minimize(loss.objective, init, jac = loss.objective_jac, constraints = cons, method='SLSQP',options={'maxiter': maxiter, 'disp': True})\n",
    "print(res)\n",
    "print(rho_pois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
