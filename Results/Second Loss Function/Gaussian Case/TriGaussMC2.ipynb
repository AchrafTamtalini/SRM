{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../..')\n",
    "from Library.lossSRM import LossAbs\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import math\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class for loss function of the following form :  l(x) = 1 / (1 + alpha)(1/b1 * sum(exp(b1xi)) + alpha*exp(b2*sum(xi)))- 1\n",
    "class MCLossFunction2(LossAbs):\n",
    "    def __init__(self, X, alpha, b1 = 1, b2 = 1, c = None):\n",
    "        self.__alpha = alpha\n",
    "        self.__b1 = b1\n",
    "        self.__b2 = b2\n",
    "        super(MCLossFunction2, self).__init__(X, c)\n",
    "        \n",
    "    def shortfall_risk(self, m = None):\n",
    "        m = self._check_argument(m)\n",
    "        b1, b2, alpha = self.__b1, self.__b2, self.__alpha\n",
    "        #This substract from the col i of X, m_i\n",
    "        #X is a matrix of dim columns and N rows where N is the sample's length\n",
    "        x_minus_m = np.subtract(self.X, m)\n",
    "        exp_x_minus_m = (1 / b1) * np.exp(b1 * x_minus_m)\n",
    "        #axis = 1 means we sum the elements of each row\n",
    "        mean_sum1 = np.mean(np.sum(exp_x_minus_m, axis = 1))\n",
    "        mean_sum2 = alpha * np.mean(np.exp(b2 * np.sum(x_minus_m, axis = 1)))\n",
    "        return (1 / (1 + alpha)) * (mean_sum1 + mean_sum2) - 1\n",
    "    \n",
    "    def shortfall_risk_jac(self, m):\n",
    "        m = self._check_argument(m)\n",
    "        x_minus_m = np.subtract(self.X, m)\n",
    "        common_mean = alpha * b2 * np.mean(np.exp(b2 * np.sum(x_minus_m, axis = 1)))\n",
    "        ind_mean = np.mean(np.exp(b1 * x_minus_m), axis = 0)\n",
    "        return 1 / (1 + alpha) * (ind_mean + common_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.5941049792653427\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "     fun: 0.5941049792653427\n",
      "     jac: array([1., 1., 1.])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 6\n",
      "     nit: 5\n",
      "    njev: 5\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.18083154, 0.18128586, 0.23198758])\n"
     ]
    }
   ],
   "source": [
    "#Case: rho = -0.9, alpha = 1. When alpha = 0 the results are independent of correlation\n",
    "#We choose sigma_3 higher than sigma_1 = sigma_2. We expect m3 to be higher thatn m2=m1 as it is riskier.\n",
    "\n",
    "#M is the length of the sample\n",
    "M = 2000000\n",
    "rho = -0.9\n",
    "mu = [0., 0., 0.]\n",
    "sigma = [[0.5, 0.5 * rho, 0.], [0.5 * rho, 0.5, 0.], [0., 0., 0.6]]\n",
    "\n",
    "rv = st.multivariate_normal(mean = mu, cov = sigma, allow_singular = True)\n",
    "distr = rv.rvs(size = M)\n",
    "\n",
    "alpha, b1, b2, c = 1., 1., 1., 1.\n",
    "loss = MCLossFunction2(distr, alpha, b1, b2, c)\n",
    "maxiter = 3500\n",
    "\n",
    "init =  np.zeros(loss.dim)\n",
    "cons = ({'type': 'ineq',\n",
    "         'fun' : lambda x: loss.ineq_constraint(x),\n",
    "         'jac' : lambda x: loss.ineq_constraint_jac(x)})\n",
    "res = minimize(loss.objective, init, \n",
    "              jac = loss.objective_jac, \n",
    "              constraints = cons, \n",
    "               method='SLSQP',\n",
    "               options={'maxiter': maxiter, 'disp': True})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6799813233753671\n",
      "            Iterations: 5\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 5\n",
      "     fun: 0.6799813233753671\n",
      "     jac: array([1., 1., 1.])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 6\n",
      "     nit: 5\n",
      "    njev: 5\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.21023917, 0.21039367, 0.25934848])\n"
     ]
    }
   ],
   "source": [
    "#Case: rho = -0.5, alpha = 1. When alpha = 0 the results are independent of correlation\n",
    "#We choose sigma_3 higher than sigma_1 = sigma_2. We expect m3 to be higher thatn m2=m1 as it is riskier.\n",
    "\n",
    "#M is the length of the sample\n",
    "M = 2000000\n",
    "rho = -0.5\n",
    "mu = [0., 0., 0.]\n",
    "sigma = [[0.5, 0.5 * rho, 0.], [0.5 * rho, 0.5, 0.], [0., 0., 0.6]]\n",
    "\n",
    "rv = st.multivariate_normal(mean = mu, cov = sigma, allow_singular = True)\n",
    "distr = rv.rvs(size = M)\n",
    "\n",
    "alpha, b1, b2, c = 1., 1., 1., 1.\n",
    "loss = MCLossFunction2(distr, alpha, b1, b2, c)\n",
    "maxiter = 3500\n",
    "\n",
    "init =  np.zeros(loss.dim)\n",
    "cons = ({'type': 'ineq',\n",
    "         'fun' : lambda x: loss.ineq_constraint(x),\n",
    "         'jac' : lambda x: loss.ineq_constraint_jac(x)})\n",
    "res = minimize(loss.objective, init, \n",
    "              jac = loss.objective_jac, \n",
    "              constraints = cons, \n",
    "               method='SLSQP',\n",
    "               options={'maxiter': maxiter, 'disp': True})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.7512514370242767\n",
      "            Iterations: 6\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 6\n",
      "     fun: 0.7512514370242767\n",
      "     jac: array([1., 1., 1.])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 7\n",
      "     nit: 6\n",
      "    njev: 6\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.23385645, 0.23357702, 0.28381797])\n"
     ]
    }
   ],
   "source": [
    "#Case: rho = -0.2, alpha = 1. When alpha = 0 the results are independent of correlation\n",
    "#We choose sigma_3 higher than sigma_1 = sigma_2. We expect m3 to be higher thatn m2=m1 as it is riskier.\n",
    "\n",
    "#M is the length of the sample\n",
    "M = 2000000\n",
    "rho = -0.2\n",
    "mu = [0., 0., 0.]\n",
    "sigma = [[0.5, 0.5 * rho, 0.], [0.5 * rho, 0.5, 0.], [0., 0., 0.6]]\n",
    "\n",
    "rv = st.multivariate_normal(mean = mu, cov = sigma, allow_singular = True)\n",
    "distr = rv.rvs(size = M)\n",
    "\n",
    "alpha, b1, b2, c = 1., 1., 1., 1.\n",
    "loss = MCLossFunction2(distr, alpha, b1, b2, c)\n",
    "maxiter = 3500\n",
    "\n",
    "init =  np.zeros(loss.dim)\n",
    "cons = ({'type': 'ineq',\n",
    "         'fun' : lambda x: loss.ineq_constraint(x),\n",
    "         'jac' : lambda x: loss.ineq_constraint_jac(x)})\n",
    "res = minimize(loss.objective, init, \n",
    "              jac = loss.objective_jac, \n",
    "              constraints = cons, \n",
    "               method='SLSQP',\n",
    "               options={'maxiter': maxiter, 'disp': True})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.8005721440255539\n",
      "            Iterations: 6\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 6\n",
      "     fun: 0.8005721440255539\n",
      "     jac: array([1., 1., 1.])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 7\n",
      "     nit: 6\n",
      "    njev: 6\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.25028411, 0.2507467 , 0.29954133])\n"
     ]
    }
   ],
   "source": [
    "#Case: rho = 0, alpha = 1. When alpha = 0 the results are independent of correlation\n",
    "#We choose sigma_3 higher than sigma_1 = sigma_2. We expect m3 to be higher thatn m2=m1 as it is riskier.\n",
    "\n",
    "#M is the length of the sample\n",
    "M = 2000000\n",
    "rho = 0\n",
    "mu = [0., 0., 0.]\n",
    "sigma = [[0.5, 0.5 * rho, 0.], [0.5 * rho, 0.5, 0.], [0., 0., 0.6]]\n",
    "\n",
    "rv = st.multivariate_normal(mean = mu, cov = sigma, allow_singular = True)\n",
    "distr = rv.rvs(size = M)\n",
    "\n",
    "alpha, b1, b2, c = 1., 1., 1., 1.\n",
    "loss = MCLossFunction2(distr, alpha, b1, b2, c)\n",
    "maxiter = 3500\n",
    "\n",
    "init =  np.zeros(loss.dim)\n",
    "cons = ({'type': 'ineq',\n",
    "         'fun' : lambda x: loss.ineq_constraint(x),\n",
    "         'jac' : lambda x: loss.ineq_constraint_jac(x)})\n",
    "res = minimize(loss.objective, init, \n",
    "              jac = loss.objective_jac, \n",
    "              constraints = cons, \n",
    "               method='SLSQP',\n",
    "               options={'maxiter': maxiter, 'disp': True})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.851097720342739\n",
      "            Iterations: 6\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 6\n",
      "     fun: 0.851097720342739\n",
      "     jac: array([1., 1., 1.])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 7\n",
      "     nit: 6\n",
      "    njev: 6\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.26748267, 0.2674522 , 0.31616285])\n"
     ]
    }
   ],
   "source": [
    "#Case: rho = 0.2, alpha = 1. When alpha = 0 the results are independent of correlation\n",
    "#We choose sigma_3 higher than sigma_1 = sigma_2. We expect m3 to be higher thatn m2=m1 as it is riskier.\n",
    "\n",
    "#M is the length of the sample\n",
    "M = 2000000\n",
    "rho = 0.2\n",
    "mu = [0., 0., 0.]\n",
    "sigma = [[0.5, 0.5 * rho, 0.], [0.5 * rho, 0.5, 0.], [0., 0., 0.6]]\n",
    "\n",
    "rv = st.multivariate_normal(mean = mu, cov = sigma, allow_singular = True)\n",
    "distr = rv.rvs(size = M)\n",
    "\n",
    "alpha, b1, b2, c = 1., 1., 1., 1.\n",
    "loss = MCLossFunction2(distr, alpha, b1, b2, c)\n",
    "maxiter = 3500\n",
    "\n",
    "init =  np.zeros(loss.dim)\n",
    "cons = ({'type': 'ineq',\n",
    "         'fun' : lambda x: loss.ineq_constraint(x),\n",
    "         'jac' : lambda x: loss.ineq_constraint_jac(x)})\n",
    "res = minimize(loss.objective, init, \n",
    "              jac = loss.objective_jac, \n",
    "              constraints = cons, \n",
    "               method='SLSQP',\n",
    "               options={'maxiter': maxiter, 'disp': True})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.9313964276239755\n",
      "            Iterations: 6\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 6\n",
      "     fun: 0.9313964276239755\n",
      "     jac: array([1., 1., 1.])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 7\n",
      "     nit: 6\n",
      "    njev: 6\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.29484536, 0.2942223 , 0.34232877])\n"
     ]
    }
   ],
   "source": [
    "#Case: rho = 0.5, alpha = 1. When alpha = 0 the results are independent of correlation\n",
    "#We choose sigma_3 higher than sigma_1 = sigma_2. We expect m3 to be higher thatn m2=m1 as it is riskier.\n",
    "\n",
    "#M is the length of the sample\n",
    "M = 2000000\n",
    "rho = 0.5\n",
    "mu = [0., 0., 0.]\n",
    "sigma = [[0.5, 0.5 * rho, 0.], [0.5 * rho, 0.5, 0.], [0., 0., 0.6]]\n",
    "\n",
    "rv = st.multivariate_normal(mean = mu, cov = sigma, allow_singular = True)\n",
    "distr = rv.rvs(size = M)\n",
    "\n",
    "alpha, b1, b2, c = 1., 1., 1., 1.\n",
    "loss = MCLossFunction2(distr, alpha, b1, b2, c)\n",
    "maxiter = 3500\n",
    "\n",
    "init =  np.zeros(loss.dim)\n",
    "cons = ({'type': 'ineq',\n",
    "         'fun' : lambda x: loss.ineq_constraint(x),\n",
    "         'jac' : lambda x: loss.ineq_constraint_jac(x)})\n",
    "res = minimize(loss.objective, init, \n",
    "              jac = loss.objective_jac, \n",
    "              constraints = cons, \n",
    "               method='SLSQP',\n",
    "               options={'maxiter': maxiter, 'disp': True})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 1.0415828440871808\n",
      "            Iterations: 6\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 6\n",
      "     fun: 1.0415828440871808\n",
      "     jac: array([1., 1., 1.])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 7\n",
      "     nit: 6\n",
      "    njev: 6\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.33163786, 0.33100826, 0.37893673])\n"
     ]
    }
   ],
   "source": [
    "#Case: rho = 0.9, alpha = 1. When alpha = 0 the results are independent of correlation\n",
    "#We choose sigma_3 higher than sigma_1 = sigma_2. We expect m3 to be higher thatn m2=m1 as it is riskier.\n",
    "\n",
    "#M is the length of the sample\n",
    "M = 2000000\n",
    "rho = 0.9\n",
    "mu = [0., 0., 0.]\n",
    "sigma = [[0.5, 0.5 * rho, 0.], [0.5 * rho, 0.5, 0.], [0., 0., 0.6]]\n",
    "\n",
    "rv = st.multivariate_normal(mean = mu, cov = sigma, allow_singular = True)\n",
    "distr = rv.rvs(size = M)\n",
    "\n",
    "alpha, b1, b2, c = 1., 1., 1., 1.\n",
    "loss = MCLossFunction2(distr, alpha, b1, b2, c)\n",
    "maxiter = 3500\n",
    "\n",
    "init =  np.zeros(loss.dim)\n",
    "cons = ({'type': 'ineq',\n",
    "         'fun' : lambda x: loss.ineq_constraint(x),\n",
    "         'jac' : lambda x: loss.ineq_constraint_jac(x)})\n",
    "res = minimize(loss.objective, init, \n",
    "              jac = loss.objective_jac, \n",
    "              constraints = cons, \n",
    "               method='SLSQP',\n",
    "               options={'maxiter': maxiter, 'disp': True})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
